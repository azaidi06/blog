[
  {
    "objectID": "posts/koala-series/koala.html",
    "href": "posts/koala-series/koala.html",
    "title": "A series of Koalas",
    "section": "",
    "text": "Sunrise\n\n\n\nJust hanging out\n\n\n\n<3"
  },
  {
    "objectID": "posts/nb_tutorial/nb_tutorial.html",
    "href": "posts/nb_tutorial/nb_tutorial.html",
    "title": "Authoring delightful documents with Notebooks!",
    "section": "",
    "text": "Code\nTo use a jupyter notebook like this, include the following as raw a cell at the top of your notebook:<br>\ntitle: \"Authoring delightful documents with Notebooks!\"<br>\nauthor: \"Ali Zaidi\"<br>\ndate: \"2022-10-21\"<br>\ncategories: []<br>\ntoc: true<br>\ntoc-depth: 3<br>\ntoc-title: Contents<br>\nimage: \"notebook.png\"<br>\nnumber-sections: true<br>\nformat:<br>\n    html:<br>\n        code-fold: true<br>\n        code-tools: true<br>\nkeep-ipynb: true <br>\njupyter: python3<br>"
  },
  {
    "objectID": "posts/nb_tutorial/nb_tutorial.html#seeing-our-first-plot",
    "href": "posts/nb_tutorial/nb_tutorial.html#seeing-our-first-plot",
    "title": "Authoring delightful documents with Notebooks!",
    "section": "1.1 Seeing our first plot",
    "text": "1.1 Seeing our first plot\n\n1.1.1 Random level in\nJust to show toc-depth field (table of content)\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nx = np.arange(10)\ny = np.random.randint(0, 10, 10)\nplt.plot(x,y)\nplt.title('A random plot!')\nplt.xlabel('our x axis :-p')\nplt.ylabel('our y values');\n\n\n\n\n\na simple plot!\n\n\n\n\n\n\nCode\nnp.array([x,y]).T.shape\n\n\n(10, 2)"
  },
  {
    "objectID": "posts/nb_tutorial/nb_tutorial.html#dataframes-as-well",
    "href": "posts/nb_tutorial/nb_tutorial.html#dataframes-as-well",
    "title": "Authoring delightful documents with Notebooks!",
    "section": "1.2 Dataframes as well!",
    "text": "1.2 Dataframes as well!\n\n\n\n\n\n\n  \n    \n      \n      y1\n      y2\n      y3\n    \n  \n  \n    \n      0\n      5.0\n      8.0\n      2.5\n    \n    \n      1\n      6.0\n      9.0\n      3.0\n    \n    \n      2\n      8.0\n      11.0\n      4.0\n    \n    \n      3\n      1.0\n      4.0\n      0.5\n    \n    \n      4\n      6.0\n      9.0\n      3.0\n    \n    \n      5\n      4.0\n      7.0\n      2.0\n    \n    \n      6\n      4.0\n      7.0\n      2.0\n    \n    \n      7\n      3.0\n      6.0\n      1.5\n    \n    \n      8\n      3.0\n      6.0\n      1.5\n    \n    \n      9\n      3.0\n      6.0\n      1.5"
  },
  {
    "objectID": "posts/nn-activations/activations_nb.html",
    "href": "posts/nn-activations/activations_nb.html",
    "title": "Ali Zaidi",
    "section": "",
    "text": "::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nfrom __future__ import annotations\nimport random,math,torch,numpy as np,matplotlib.pyplot as plt\nimport fastcore.all as fc\nfrom functools import partial\n\nfrom miniai.datasets import *\nfrom miniai.learner import *\n:::\n\nimport torch.nn.functional as F,matplotlib as mpl\nfrom pathlib import Path\nfrom operator import attrgetter,itemgetter\nfrom contextlib import contextmanager\n\nfrom torch import tensor,nn,optim\nimport torchvision.transforms.functional as TF\nfrom datasets import load_dataset\n\nfrom fastcore.test import test_close\n\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\nmpl.rcParams['figure.constrained_layout.use'] = True\n\nimport logging\nlogging.disable(logging.WARNING)\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef set_seed(seed, deterministic=False):\n    torch.use_deterministic_algorithms(deterministic)\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n:::\n\nx,y = 'image','label'\nname = \"fashion_mnist\"\ndsd = load_dataset(name)\nbs = 1024\n\n@inplace\ndef transformi(b): b[x] = [TF.to_tensor(o) for o in b[x]]\n\ntds = dsd.with_transform(transformi)\ndls = DataLoaders.from_dd(tds, bs, num_workers=4)\ndt = dls.train\n\n\n\n\n\n\n\ndef conv(ni, nf, ks=3, act=True):\n    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)\n    if act: res = nn.Sequential(res, nn.ReLU())\n    return res\n\ndef cnn_layers():\n    return [\n        conv(1 ,8, ks=5),        #14x14\n        conv(8 ,16),             #7x7\n        conv(16,32),             #4x4\n        conv(32,64),             #2x2\n        conv(64,10, act=False),  #1x1\n        nn.Flatten()]\n\nWe want to train quickly, so that means training at a high learning rate.\n\nfrom torcheval.metrics import MulticlassAccuracy\n\n\nmetrics = MetricsCB(accuracy=MulticlassAccuracy())\ncbs = [TrainCB(), DeviceCB(), metrics, ProgressCB(plot=True)]\n\n\ndef fit(model, epochs=1, xtra_cbs=None):\n    learn = Learner(model, dls, loss_func=F.cross_entropy, lr=0.6, cbs=cbs+fc.L(xtra_cbs))\n    learn.fit(epochs)\n    return learn\n\n\nset_seed(1)\nlearn = fit(nn.Sequential(*cnn_layers()))\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.208\n      2.243\n      0\n      train\n    \n    \n      0.204\n      2.165\n      0\n      eval\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nclass SequentialModel(nn.Module):\n    def __init__(self, *layers):\n        super().__init__()\n        self.layers = nn.ModuleList(layers)\n        self.act_means = [[] for _ in layers]\n        self.act_stds  = [[] for _ in layers]\n        \n    def __call__(self, x):\n        for i,l in enumerate(self.layers):\n            x = l(x)\n            self.act_means[i].append(to_cpu(x).mean())\n            self.act_stds [i].append(to_cpu(x).std ())\n        return x\n    \n    def __iter__(self): return iter(self.layers)\n\n\nset_seed(1)\nmodel = SequentialModel(*cnn_layers())\nlearn = fit(model)\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.247\n      2.110\n      0\n      train\n    \n    \n      0.376\n      1.659\n      0\n      eval\n    \n  \n\n\n\n\n\n\n\nfor l in model.act_means: plt.plot(l)\nplt.legend(range(5));\n\n\n\n\n\nfor l in model.act_stds: plt.plot(l)\nplt.legend(range(5));\n\n\n\n\n\n\n\nHooks are PyTorch object you can add to any nn.Module. A hook will be called when a layer, it is registered to, is executed during the forward pass (forward hook) or the backward pass (backward hook). Hooks don’t require us to rewrite the model.\n\nset_seed(1)\nmodel = nn.Sequential(*cnn_layers())\n\nA hook is attached to a layer, and needs to have a function that takes three arguments: module, input, output. Here we store the mean and std of the output in the correct position of our list.\n\nact_means = [[] for _ in model]\nact_stds  = [[] for _ in model]\n\n\ndef append_stats(i, mod, inp, outp):\n    act_means[i].append(to_cpu(outp).mean())\n    act_stds [i].append(to_cpu(outp).std())\n\n\nfor i,m in enumerate(model): m.register_forward_hook(partial(append_stats, i))\n\n\nfit(model)\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.263\n      2.091\n      0\n      train\n    \n    \n      0.164\n      2.245\n      0\n      eval\n    \n  \n\n\n\n\n\n\n<miniai.learner.Learner>\n\n\n\nfor o in act_means: plt.plot(o)\nplt.legend(range(5));\n\n\n\n\n\n\n\nWe can refactor this in a Hook class. It’s very important to remove the hooks when they are deleted, otherwise there will be references kept and the memory won’t be properly released when your model is deleted.\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass Hook():\n    def __init__(self, m, f): self.hook = m.register_forward_hook(partial(f, self))\n    def remove(self): self.hook.remove()\n    def __del__(self): self.remove()\n:::\n\ndef append_stats(hook, mod, inp, outp):\n    if not hasattr(hook,'stats'): hook.stats = ([],[])\n    acts = to_cpu(outp)\n    hook.stats[0].append(acts.mean())\n    hook.stats[1].append(acts.std())\n\n\nset_seed(1)\nmodel = nn.Sequential(*cnn_layers())\n\n\nhooks = [Hook(l, append_stats) for l in model[:5].children()]\n\n\nlearn = fit(model)\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.247\n      2.122\n      0\n      train\n    \n    \n      0.397\n      1.456\n      0\n      eval\n    \n  \n\n\n\n\n\n\n\nfor h in hooks:\n    plt.plot(h.stats[0])\n    h.remove()\nplt.legend(range(5));\n\n\n\n\n\n\n\n\nclass DummyCtxMgr:\n    def __enter__(self, *args):\n        print(\"let's go!\")\n        return self\n    def __exit__ (self, *args): print(\"all done!\")\n    def hello(self): print(\"hello.\")\n\n\nwith DummyCtxMgr() as dcm: dcm.hello()\n\nlet's go!\nhello.\nall done!\n\n\n\nclass DummyList(list):\n    def __delitem__(self, i):\n        print(f\"Say bye to item {i}\")\n        super().__delitem__(i)\n\n\ndml = DummyList([1,3,2])\ndml\n\n[1, 3, 2]\n\n\n\ndel(dml[2])\ndml\n\nSay bye to item 2\n\n\n[1, 3]\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass Hooks(list):\n    def __init__(self, ms, f): super().__init__([Hook(m, f) for m in ms])\n    def __enter__(self, *args): return self\n    def __exit__ (self, *args): self.remove()\n    def __del__(self): self.remove()\n    def __delitem__(self, i):\n        self[i].remove()\n        super().__delitem__(i)\n    def remove(self):\n        for h in self: h.remove()\n:::\n\nset_seed(1)\nmodel = nn.Sequential(*cnn_layers())\n\n\nwith Hooks(model, append_stats) as hooks:\n    fit(model)\n    fig,axs = plt.subplots(1,2, figsize=(10,4))\n    for h in hooks:\n        for i in 0,1: axs[i].plot(h.stats[i])\n    plt.legend(range(6));\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.166\n      2.475\n      0\n      train\n    \n    \n      0.100\n      2.303\n      0\n      eval\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass HooksCallback(Callback):\n    def __init__(self, hookfunc, mod_filter=fc.noop, on_train=True, on_valid=False, mods=None):\n        fc.store_attr()\n        super().__init__()\n    \n    def before_fit(self, learn):\n        if self.mods: mods=self.mods\n        else: mods = fc.filter_ex(learn.model.modules(), self.mod_filter)\n        self.hooks = Hooks(mods, partial(self._hookfunc, learn))\n\n    def _hookfunc(self, learn, *args, **kwargs):\n        if (self.on_train and learn.training) or (self.on_valid and not learn.training): self.hookfunc(*args, **kwargs)\n\n    def after_fit(self, learn): self.hooks.remove()\n    def __iter__(self): return iter(self.hooks)\n    def __len__(self): return len(self.hooks)\n:::\n\nhc = HooksCallback(append_stats, mod_filter=fc.risinstance(nn.Conv2d))\n\n\nset_seed(1)\nmodel = nn.Sequential(*cnn_layers())\nfit(model, xtra_cbs=[hc]);\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.205\n      2.232\n      0\n      train\n    \n    \n      0.100\n      2.305\n      0\n      eval\n    \n  \n\n\n\n\n\n\n\nfig,axs = plt.subplots(1,2, figsize=(10,4))\nfor h in hc:\n    for i in 0,1: axs[i].plot(h.stats[i])\nplt.legend(range(6));\n\n\n\n\n\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef append_stats(hook, mod, inp, outp):\n    if not hasattr(hook,'stats'): hook.stats = ([],[],[])\n    acts = to_cpu(outp)\n    hook.stats[0].append(acts.mean())\n    hook.stats[1].append(acts.std())\n    hook.stats[2].append(acts.abs().histc(40,0,10))\n:::\n\nset_seed(1)\nmodel = nn.Sequential(*cnn_layers())\nhc = HooksCallback(append_stats, mod_filter=fc.risinstance(nn.Conv2d))\nfit(model, xtra_cbs=[hc]);\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.213\n      2.379\n      0\n      train\n    \n    \n      0.100\n      21.771\n      0\n      eval\n    \n  \n\n\n\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\n# Thanks to @ste for initial version of histgram plotting code\ndef get_hist(h): return torch.stack(h.stats[2]).t().float().log1p()\n:::\n\nfig,axes = get_grid(len(hc), figsize=(11,5))\nfor ax,h in zip(axes.flat, hc):\n    show_image(get_hist(h), ax, origin='lower')\n\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef get_min(h):\n    h1 = torch.stack(h.stats[2]).t().float()\n    return h1[0]/h1.sum(0)\n:::\n\nfig,axes = get_grid(len(hc), figsize=(11,5))\nfor ax,h in zip(axes.flatten(), hc):\n    ax.plot(get_min(h))\n    ax.set_ylim(0,1)\n\n\n\n\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass ActivationStats(HooksCallback):\n    def __init__(self, mod_filter=fc.noop): super().__init__(append_stats, mod_filter)\n\n    def color_dim(self, figsize=(11,5)):\n        fig,axes = get_grid(len(self), figsize=figsize)\n        for ax,h in zip(axes.flat, self):\n            show_image(get_hist(h), ax, origin='lower')\n\n    def dead_chart(self, figsize=(11,5)):\n        fig,axes = get_grid(len(self), figsize=figsize)\n        for ax,h in zip(axes.flatten(), self):\n            ax.plot(get_min(h))\n            ax.set_ylim(0,1)\n\n    def plot_stats(self, figsize=(10,4)):\n        fig,axs = plt.subplots(1,2, figsize=figsize)\n        for h in self:\n            for i in 0,1: axs[i].plot(h.stats[i])\n        axs[0].set_title('Means')\n        axs[1].set_title('Stdevs')\n        plt.legend(fc.L.range(self))\n:::\n\nastats = ActivationStats(fc.risinstance(nn.Conv2d))\n\n\nset_seed(1)\nmodel = nn.Sequential(*cnn_layers())\nfit(model, xtra_cbs=[astats]);\n\n\n\n\n\n\n\n  \n    \n      accuracy\n      loss\n      epoch\n      train\n    \n  \n  \n    \n      0.208\n      2.199\n      0\n      train\n    \n    \n      0.289\n      1.695\n      0\n      eval\n    \n  \n\n\n\n\n\n\n\nastats.color_dim()\n\n\n\n\n\nastats.dead_chart()\n\n\n\n\n\nastats.plot_stats()\n\n\n\n\n\n\n\n\nimport nbdev; nbdev.nbdev_export()"
  },
  {
    "objectID": "posts/quarto_tutorial/blog_tutorial.html",
    "href": "posts/quarto_tutorial/blog_tutorial.html",
    "title": "Making a blog",
    "section": "",
    "text": "2 Where would you even begin to start a blog?\nIf you wanted to bypass doing any setup work - you could create profile on Medium (or something similar) and start posting there. While I’m sure it’s an excellent option, creating your own blog provides the opportunity to customize everything and be in control. At some point (a few years ago) I decided I should heed this advice, but I also convinced myself that I needed to create the website from scratch with Django. After about a day or two of (what felt like) banging my head, I came to my senses and gave up. \nLuckily, with Quarto things couldn’t be easier! This post is based on the work of other wonderful posts that I found on the Fast.AI forums (one) (two) – along with some perusing of the Quarto docs.\n\n\n3 How can you build one with Quarto?"
  },
  {
    "objectID": "posts/cats-series/cats.html",
    "href": "posts/cats-series/cats.html",
    "title": "A series of Cats",
    "section": "",
    "text": "Yum\n\n\n\nFun\n\n\n\nWho said cats can’t play tennis?\n\n\n\n\n\nWe love using our paws"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ali Zaidi",
    "section": "",
    "text": "Activation stats\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nA series of Koalas\n\n\n\n\n\n\n\nArt\n\n\nRandom\n\n\nFun\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMaking a blog\n\n\n\n\n\n\n\nTutorial\n\n\nProgramming\n\n\n\n\nBlogging made easy, for anyone!\n\n\n\n\n\n\nNov 6, 2022\n\n\n\n\n\n\n  \n\n\n\n\nA series of Cats\n\n\n\n\n\n\n\nArt\n\n\nRandom\n\n\nFun\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2022\n\n\n\n\n\n\n  \n\n\n\n\nAuthoring delightful documents with Notebooks!\n\n\n\n\n\n\n\nTutorial\n\n\nProgramming\n\n\n\n\nTechnical documentation made easy\n\n\n\n\n\n\nOct 21, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ali Zaidi",
    "section": "",
    "text": "Some other ways to find me"
  }
]